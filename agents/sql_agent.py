"""
Text-to-SQLæ™ºèƒ½ä½“
"""
import re
from typing import Dict, Any, List, Optional
import requests
from sqlalchemy import text
from models.database import SessionLocal
from config import config
from utils.logger import app_logger
from utils.helpers import MessageFormatter, DateTimeHelper
from typing import Optional
from utils.mschema_helper import get_db_schema

class SQLAgent:
    """SQLæŸ¥è¯¢æ™ºèƒ½ä½“"""
    
    def __init__(self):
        # å»¶è¿Ÿåˆå§‹åŒ–LLMï¼Œé¿å…å¯¼å…¥å†²çª
        self.llm = None
        # llm_mode: None / 'langchain' / 'openai_direct'
        self.llm_mode = None
        
        # æ•°æ®åº“è¡¨ç»“æ„ä¿¡æ¯
        self.schema_info = self._get_schema_info()
        # M-Schema å­—ç¬¦ä¸²ç¼“å­˜ï¼ˆæ‡’åŠ è½½ï¼‰
        self._mschema_str: Optional[str] = None
        
        # æç¤ºæ¨¡æ¿å’Œé“¾åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶åˆ›å»º
        self.sql_prompt = None
        self.chain = None

    def _ensure_chain(self):
        """ç¡®ä¿LLMå’ŒChainå·²åˆå§‹åŒ–"""
        if self.llm is None:
            # è‹¥é…ç½®å¼ºåˆ¶ç›´è¿æ¨¡å¼ï¼Œåˆ™ç›´æ¥å¯ç”¨ç›´è¿
            force_mode = getattr(config, 'SQL_AGENT_MODE', 'auto')
            api_key = getattr(config, 'OPENAI_API_KEY', '') or ''
            if force_mode == 'direct':
                if (not api_key) or (api_key.strip().lower() in {"your-openai-api-key", "sk-your-openai-api-key"}):
                    app_logger.warning("OPENAI_API_KEY æœªé…ç½®æˆ–ä¸ºå ä½ç¬¦ï¼ŒSQLAgentä½¿ç”¨è§„åˆ™åŒ–å›é€€")
                    return
                self.llm = 'openai_direct'
                self.llm_mode = 'openai_direct'
                app_logger.info("SQLAgent å·²æŒ‰é…ç½®å¼ºåˆ¶ä½¿ç”¨ OpenAI ç›´è¿æ¨¡å¼")
                # ç›´è¿æ¨¡å¼ä¸éœ€è¦ chain
                return
            # è‹¥æœªé…ç½®APIå¯†é’¥æˆ–ä½¿ç”¨å ä½ç¬¦ï¼Œåˆ™ä¸åˆå§‹åŒ–LLMï¼Œèµ°è§„åˆ™åŒ–å›é€€
            if (not api_key) or (api_key.strip().lower() in {"your-openai-api-key", "sk-your-openai-api-key"}):
                app_logger.warning("OPENAI_API_KEY æœªé…ç½®æˆ–ä¸ºå ä½ç¬¦ï¼ŒSQLAgentä½¿ç”¨è§„åˆ™åŒ–å›é€€")
                return
            # ä¼˜å…ˆå°è¯•ä½¿ç”¨ LangChain OpenAIï¼›è‹¥å¯¼å…¥æˆ–ä¾èµ–å¤±è´¥ï¼Œåˆ™é€€å› OpenAI ç›´è¿æ¨¡å¼
            try:
                # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¯åŠ¨æ—¶åŠ è½½transformers/torch
                from langchain_openai import ChatOpenAI
                from langchain_core.prompts import ChatPromptTemplate
                self.llm = ChatOpenAI(
                    model=getattr(config, 'OPENAI_MODEL', 'default'),
                    api_key=config.OPENAI_API_KEY,
                    base_url=getattr(config, 'OPENAI_BASE_URL', ''),
                    temperature=0.1
                )
                self.llm_mode = 'langchain'
                if self.sql_prompt is None:
                    self.sql_prompt = ChatPromptTemplate.from_messages([
                        ("system", self._get_system_prompt()),
                        ("human", "ç”¨æˆ·æŸ¥è¯¢ï¼š{query}\n\nä¼šè¯ä¸Šä¸‹æ–‡ï¼ˆæœ€è¿‘å‡ è½®ï¼‰ï¼š\n{history}\n\né™„åŠ æ•°æ®åº“ç†è§£ï¼ˆM-Schemaï¼‰ï¼š\n{mschema}\nè¯·ç”Ÿæˆå¯¹åº”çš„SQLæŸ¥è¯¢è¯­å¥ã€‚ä»…è¾“å‡ºSQLï¼Œä¸è¦è§£é‡Šã€‚ä¸è¦ä½¿ç”¨åå¼•å·ã€‚")
                    ])
                app_logger.info("SQLAgent å·²ä½¿ç”¨ LangChain OpenAI åˆå§‹åŒ–")
            except Exception as e:
                # å›é€€åˆ°ç›´è¿ OpenAI æ¨¡å¼ï¼Œä¸ä¾èµ– transformers/torch
                self.llm = 'openai_direct'
                self.llm_mode = 'openai_direct'
                app_logger.warning(f"LangChain åˆå§‹åŒ–å¤±è´¥ï¼Œæ”¹ç”¨ OpenAI ç›´è¿æ¨¡å¼ï¼š{e}")
        if self.chain is None and self.llm is not None:
            # ä»…åœ¨ä½¿ç”¨ LangChain æ—¶åˆ›å»º chain
            if self.llm_mode == 'langchain':
                self.chain = self.sql_prompt | self.llm
    
    def _get_schema_info(self) -> str:
        """è·å–æ•°æ®åº“è¡¨ç»“æ„ä¿¡æ¯"""
        return """
æ•°æ®åº“è¡¨ç»“æ„ï¼ˆç®€åŒ–è¯´æ˜ï¼Œç”¨äºæŒ‡å¯¼LLMç”Ÿæˆæ­£ç¡®çš„å­—æ®µåï¼‰ï¼š

1. staff_mapping (å‘˜å·¥æ˜ å°„è¡¨)
   - staff_id: å‘˜å·¥ID (å”¯ä¸€ï¼Œä½¿ç”¨ç¾¤å†…å‰ç¼€æ˜µç§°ï¼Œå¦‚ SM_/HP_/XS_)
   - role: è§’è‰² (ç¤¾åª’/åˆä¼™äºº/é”€å”®)
   - is_active: æ˜¯å¦æ¿€æ´»
   - created_at, updated_at

2. parents (å®¶é•¿ä¿¡æ¯è¡¨)
   - id: ä¸»é”®ID
   - parent_code: å®¶é•¿ç¼–å· (ä»¥ P å¼€å¤´)
   - source_platform: æ¥æºå¹³å° (æŠ–éŸ³/å°çº¢ä¹¦/...)
   - service_category: ä¸šåŠ¡ç±»å‹ (DSE/ç•™å­¦/æ¸¸å­¦/å…¶ä»–)
   - intent_level: æ„å‘åº¦ (ä½/ä¸­/é«˜)
   - current_status: å½“å‰çŠ¶æ€ (å¾…æ¥æ‰‹/åˆä¼™äººè·Ÿè¿›ä¸­/é”€å”®è·Ÿè¿›ä¸­/å·²æˆäº¤/å·²æµå¤±)
   - social_media_id: ç¤¾åª’äººå‘˜ID
   - partner_id: åˆä¼™äººID
   - salesperson_id: é”€å”®äººå‘˜ID
   - deal_amount: æˆäº¤é‡‘é¢
   - created_at, updated_at

3. parent_contacts (å®¶é•¿è”ç³»æ–¹å¼è¡¨)
   - parent_id: å®¶é•¿ID (å¤–é”®)
   - contact_type: è”ç³»æ–¹å¼ç±»å‹ (å¾®ä¿¡å·/æ‰‹æœºå·/é¦™æ¸¯WSæ‰‹æœºå·/å¾®ä¿¡äºŒç»´ç æ˜µç§°)
   - contact_value: è”ç³»æ–¹å¼å€¼
   - contact_desc: è¯´æ˜
   - is_primary: æ˜¯å¦ä¸»è¦è”ç³»æ–¹å¼
   - created_at, updated_at

4. process_logs (å¤„ç†æ—¥å¿—è¡¨)
   - parent_id: å®¶é•¿ID
   - action_type: æ“ä½œç±»å‹ (æ–°å®¶é•¿/è¡¥å…¨å¾®ä¿¡å·/æ¥æ‰‹/æ”¾å¼ƒ/è½¬é”€å”®/é”€å”®æ¥æ‰‹/æˆäº¤/æµå¤±/åé¦ˆ)
   - operator_id, operator_role
   - message_content, notes
   - created_at

5. followup_feedback (è·Ÿè¿›åé¦ˆè¡¨)
   - parent_id: å®¶é•¿ID
   - feedback_type: åé¦ˆç±»å‹
   - content: åé¦ˆå†…å®¹
   - is_dse: æ˜¯å¦DSE
  - operator_id
  - created_at
"""

    def _get_mschema_str(self) -> str:
        """è·å– M-Schema å­—ç¬¦ä¸²ï¼ˆå¸¦ç¼“å­˜ï¼‰ã€‚"""
        if not self._mschema_str:
            # ä¸ example.py å¯¹é½ï¼šä½¿ç”¨ db_schemaï¼ˆåº•å±‚ä»ä¸º M-Schema å­—ç¬¦ä¸²ï¼‰
            self._mschema_str = get_db_schema()
        return self._mschema_str
    
    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤º"""

        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ SQL æŸ¥è¯¢ç”ŸæˆåŠ©æ‰‹ï¼Œä¸“é—¨ä¸ºå®¶é•¿çº¿ç´¢ç®¡ç†ç³»ç»Ÿç”Ÿæˆ SQL æŸ¥è¯¢ã€‚

ã€ç®€åŒ–ç»“æ„è¯´æ˜ï¼ˆå…³é”®è¡¨/å­—æ®µï¼‰ã€‘
{self.schema_info}

ã€æ€è€ƒæµç¨‹ã€‘ï¼ˆä¸¥æ ¼æ‰§è¡Œï¼‰
- ä¸€æ­¥ä¸€æ­¥åˆ†æç”¨æˆ·é—®é¢˜ï¼Œè¯†åˆ«æ—¶é—´èŒƒå›´ã€ç›®æ ‡å®ä½“ä¸éœ€è¦çš„å­—æ®µã€‚
 - SQL ç”Ÿæˆåè¯„ä¼°å…¶æ­£ç¡®æ€§ä¸å®‰å…¨æ€§ï¼ˆä»…å…è®¸ SELECTï¼‰ã€‚
- å¦‚è¯„ä¼°å¤±è´¥æˆ–å­˜åœ¨é—®é¢˜ï¼ŒSQL å¤±è´¥é‡æ–°ç”Ÿæˆå¹¶ä¿®æ­£ï¼Œç¡®ä¿å¯æ‰§è¡Œã€‚

ã€æŸ¥è¯¢ä¸è¯­æ³•è§„åˆ™ã€‘
1. åªç”Ÿæˆ SELECT æŸ¥è¯¢ï¼Œä¸è¦ç”Ÿæˆ INSERT/UPDATE/DELETE/DDL ç­‰ä¿®æ”¹è¯­å¥ã€‚
2. ä½¿ç”¨æ ‡å‡†çš„ MySQL è¯­æ³•ã€‚
3. æ—¶é—´è¿‡æ»¤ï¼š
   - â€œä»Šå¤©/å½“æ—¥â€ ä½¿ç”¨ DATE(created_at) = CURDATE()
   - â€œæœ¬å‘¨/è¿™å‘¨â€ ä½¿ç”¨ YEARWEEK(created_at, 1) = YEARWEEK(CURDATE(), 1)
   - â€œè¿‡å»ä¸€å‘¨/è¿‘ä¸€å‘¨/ä¸€å‘¨â€ ä½¿ç”¨ DATE(created_at) >= DATE_SUB(CURDATE(), INTERVAL 7 DAY)
4. å½“ç”¨æˆ·æ„å›¾ä¸º â€œåç§°/åå•/åˆ—è¡¨/æ˜ç»†/è¯¦æƒ…/åå­—â€ æ—¶ï¼Œè¿”å›æ˜ç»†åˆ—è¡¨ï¼Œä¸è¦ç»Ÿè®¡æ•°é‡ã€‚
   - å°†â€œå®¶é•¿åç§°â€è§†ä¸º parents.parent_codeï¼ˆç³»ç»Ÿæ—  parent_name å­—æ®µï¼‰ã€‚
5. å…³è”è§„åˆ™ï¼šå½“å…³è” parent_contacts æ—¶ï¼Œå¿…é¡»ä½¿ç”¨ parents.id = parent_contacts.parent_id è¿›è¡Œè¿æ¥ã€‚
6. èšåˆè§„åˆ™ï¼šè‹¥ SELECT ä¸­åŒ…å«èšåˆå‡½æ•°ï¼ˆCOUNT/SUM/AVG/MIN/MAXï¼‰ï¼Œæ‰€æœ‰éèšåˆåˆ—å¿…é¡»åœ¨ GROUP BY ä¸­ã€‚
7. è”ç³»æ–¹å¼è¿‡æ»¤ï¼šé™¤éç”¨æˆ·æ˜ç¡®è¦æ±‚â€œå·²éªŒè¯/éªŒè¯è¿‡/çœŸå®â€ï¼Œä¸è¦åŠ å…¥ is_verified = 1 æ¡ä»¶ï¼›å¦‚éœ€ä¸»è”ç³»æ–¹å¼ï¼Œä»…ä½¿ç”¨ is_primary = 1ã€‚
8. å…¼å®¹æ€§ï¼šé¿å…åœ¨ IN/EXISTS å­æŸ¥è¯¢ä¸­ä½¿ç”¨ LIMITï¼Œå¯æ”¹ä¸º JOIN æ´¾ç”Ÿè¡¨å®ç°é™åˆ¶ã€‚
9. è¿”å›çš„ SQL å¿…é¡»æ˜¯å®Œæ•´ã€å¯æ‰§è¡Œçš„ï¼›åªè¿”å› SQLï¼Œä¸è¦åŒ…å«è§£é‡Šæˆ–åå¼•å·ã€‚

ã€ç¤ºä¾‹ã€‘
- ä»Šå¤©æ–°å¢çš„å®¶é•¿æ•°é‡ï¼šSELECT COUNT(*) FROM parents WHERE DATE(created_at) = CURDATE();
- æœ¬å‘¨å®¶é•¿ç¼–å·åˆ—è¡¨ï¼šSELECT parent_code FROM parents WHERE YEARWEEK(created_at, 1) = YEARWEEK(CURDATE(), 1) ORDER BY created_at DESC LIMIT 50;
"""
    
    async def generate_sql(self, query: str, history: Optional[str] = None) -> str:
        """ç”ŸæˆSQLæŸ¥è¯¢è¯­å¥"""
        try:
            # ç¡®ä¿é“¾å·²åˆå§‹åŒ–
            self._ensure_chain()
            if self.llm is None:
                # è§„åˆ™åŒ–å›é€€
                sql = self._rule_based_sql(query)
            else:
                if self.llm_mode == 'langchain' and self.chain is not None:
                    response = await self.chain.ainvoke({"query": query, "mschema": self._get_mschema_str(), "history": (history or "")})
                    sql = response.content.strip()
                elif self.llm_mode == 'openai_direct':
                    sql = self._llm_generate_sql_openai(query, history)
                else:
                    # æœªçŸ¥æ¨¡å¼ï¼Œå›é€€è§„åˆ™
                    sql = self._rule_based_sql(query)
            
            # æ¸…ç†SQLè¯­å¥ï¼Œç§»é™¤å¯èƒ½çš„markdownæ ¼å¼
            if sql.startswith("```sql"):
                sql = sql[6:]
            if sql.startswith("```"):
                sql = sql[3:]
            if sql.endswith("```"):
                sql = sql[:-3]
            
            sql = sql.strip()
            # LLM/è§„åˆ™ç”Ÿæˆåè¿›è¡Œè‡ªæ£€ä¸ä¿®æ­£
            sql = self._review_and_fix_sql(query, sql)
            
            app_logger.info(f"ç”ŸæˆSQL: {sql}")
            return sql
            
        except Exception as e:
            app_logger.error(f"ç”ŸæˆSQLå¤±è´¥: {e}")
            raise Exception(f"ç”ŸæˆSQLæŸ¥è¯¢å¤±è´¥: {str(e)}")

    def _rule_based_sql(self, query: str) -> str:
        """åœ¨æœªé…ç½®LLMæ—¶çš„ç®€å•è§„åˆ™åŒ–SQLç”Ÿæˆ"""
        q = query.lower()
        wants_list = self._wants_list(query)
        # 1) ä»Šå¤©æ–°å¢å®¶é•¿æ•°é‡
        if ("ä»Šå¤©" in q or "ä»Šæ—¥" in q) and ("æ–°å¢" in q) and ("å®¶é•¿" in q) and not wants_list:
            return "SELECT COUNT(*) AS total FROM parents WHERE DATE(created_at) = CURDATE()"
        # ä»Šå¤©çš„å®¶é•¿åç§°/åå•
        if ("ä»Šå¤©" in q or "ä»Šæ—¥" in q) and wants_list:
            return "SELECT parent_code FROM parents WHERE DATE(created_at) = CURDATE() ORDER BY created_at DESC LIMIT 50"
        # 2) æ€»å®¶é•¿æ•°æˆ–è·Ÿè¿›ä¸­å®¶é•¿æ•°é‡
        if ("æ€»" in q or "å¤šå°‘" in q) and ("å®¶é•¿" in q) and ("è·Ÿè¿›" not in q):
            return "SELECT COUNT(*) AS total FROM parents"
        if ("è·Ÿè¿›" in q) and ("å¤šå°‘" in q or "æœ‰å¤šå°‘" in q or "æ•°é‡" in q):
            return "SELECT COUNT(*) AS total FROM parents WHERE current_status IN ('åˆä¼™äººè·Ÿè¿›ä¸­','é”€å”®è·Ÿè¿›ä¸­')"
        # 3) æœ¬æœˆæˆäº¤é‡‘é¢ï¼ˆä»¥çˆ¶è¡¨çš„æˆäº¤çŠ¶æ€ä¸æ›´æ–°æ—¶é—´ç»Ÿè®¡ï¼‰
        if ("æœ¬æœˆ" in q) and ("æˆäº¤" in q) and ("é‡‘é¢" in q):
            return (
                "SELECT COALESCE(SUM(deal_amount), 0) AS total_amount FROM parents "
                "WHERE current_status = 'å·²æˆäº¤' AND MONTH(updated_at) = MONTH(CURDATE()) "
                "AND YEAR(updated_at) = YEAR(CURDATE())"
            )
        # 4+) æœ¬å‘¨/è¿™å‘¨/ç›®å‰è¿™ä¸€å‘¨ åç§°/åå•åˆ—è¡¨
        if ("æœ¬å‘¨" in q or "è¿™å‘¨" in q or "ç›®å‰è¿™ä¸€å‘¨" in q) and wants_list:
            return (
                "SELECT parent_code FROM parents "
                "WHERE YEARWEEK(created_at, 1) = YEARWEEK(CURDATE(), 1) "
                "ORDER BY created_at DESC LIMIT 50"
            )
        # 4++) è¿‡å»ä¸€å‘¨/è¿‘ä¸€å‘¨/æœ€è¿‘ä¸€å‘¨/ä¸€å‘¨ åç§°/åå•åˆ—è¡¨
        if ("è¿‡å»ä¸€å‘¨" in q or "è¿‘ä¸€å‘¨" in q or "æœ€è¿‘ä¸€å‘¨" in q or "ä¸€å‘¨" in q) and wants_list:
            return (
                "SELECT parent_code FROM parents "
                "WHERE DATE(created_at) >= DATE_SUB(CURDATE(), INTERVAL 7 DAY) "
                "ORDER BY created_at DESC LIMIT 50"
            )
        # 4) æŸ¥è¯¢å®¶é•¿ç¼–å·è¯¦ç»†ï¼ˆå¦‚ï¼šæŸ¥è¯¢P202511057549ï¼‰
        m = re.search(r"p\s*\d{9,}", query, flags=re.IGNORECASE)
        if ("æŸ¥è¯¢" in q) and m:
            parent_code = m.group(0).upper().replace(" ", "")
            return (
                "SELECT p.parent_code, p.source_platform, p.current_status, p.partner_id, p.salesperson_id, "
                "p.intent_level, p.deal_amount, p.created_at, p.updated_at "
                "FROM parents p WHERE p.parent_code = '" + parent_code + "'"
            )
        # 5) å·²æˆäº¤å®¶é•¿åˆ—è¡¨
        if ("å·²æˆäº¤" in q) and ("æŸ¥è¯¢" in q or "æ‰€æœ‰" in q or "åˆ—è¡¨" in q):
            return (
                "SELECT parent_code, deal_amount, updated_at FROM parents "
                "WHERE current_status = 'å·²æˆäº¤' ORDER BY updated_at DESC LIMIT 50"
            )
        # 6) çŠ¶æ€ç»Ÿè®¡
        if ("çŠ¶æ€" in q) and ("ç»Ÿè®¡" in q or "åˆ†å¸ƒ" in q):
            return "SELECT current_status AS status, COUNT(*) AS count FROM parents GROUP BY current_status"
        # é»˜è®¤å…œåº•
        raise Exception("LLMæœªé…ç½®ï¼Œä¸”æ— æ³•æ ¹æ®è§„åˆ™ç”ŸæˆSQLã€‚è¯·é…ç½®æœ‰æ•ˆçš„OPENAI_API_KEYæˆ–ä½¿ç”¨æ”¯æŒçš„æŸ¥è¯¢å¥å¼ã€‚")

    def _wants_list(self, natural_query: str) -> bool:
        q = (natural_query or "").lower()
        for kw in ["åç§°", "åå•", "åˆ—è¡¨", "æ˜ç»†", "è¯¦æƒ…", "åå­—", "name", "names", "åç§°åˆ—è¡¨"]:
            if (natural_query and kw in natural_query) or (kw in q):
                return True
        return False

    def _static_sql_issues(self, sql: str, natural_query: str) -> List[str]:
        issues: List[str] = []
        s = (sql or "").strip()
        sup = s.upper()
        # é SELECT
        if not sup.startswith("SELECT"):
            issues.append("not_select")
        # èšåˆä¸ GROUP BY
        agg = re.search(r"\b(COUNT|SUM|AVG|MIN|MAX)\s*\(", sup)
        m = re.search(r"^\s*SELECT\s+(.*?)\s+FROM\s", s, flags=re.IGNORECASE | re.DOTALL)
        select_list = m.group(1) if m else ""
        group_by = re.search(r"\bGROUP\s+BY\b", sup)
        if agg and ("," in select_list) and (group_by is None):
            issues.append("aggregate_with_non_aggregate_without_group_by")
        # åç§°æ„å›¾å´è¿”å›èšåˆ
        if self._wants_list(natural_query) and agg:
            issues.append("list_intent_but_aggregate")

        # çˆ¶è¡¨ä¸è”ç³»æ–¹å¼å…³è”å­—æ®µé”™è¯¯ï¼šåº”å½“æ˜¯ parents.id = parent_contacts.parent_id
        try:
            parents_alias_m = re.search(r"\bFROM\s+parents\s+(\w+)", s, flags=re.IGNORECASE)
            pc_alias_m = re.search(r"\bJOIN\s+parent_contacts\s+(\w+)", s, flags=re.IGNORECASE)
            if parents_alias_m and pc_alias_m:
                p_alias = parents_alias_m.group(1)
                pc_alias = pc_alias_m.group(1)
                # æŸ¥æ‰¾ ON å­å¥
                on_m = re.search(rf"\bON\s+{re.escape(p_alias)}\.parent_id\s*=\s*{re.escape(pc_alias)}\.parent_id\b", s, flags=re.IGNORECASE)
                if on_m:
                    issues.append("wrong_join_parent_contacts")
        except Exception:
            pass

        # å…¼å®¹ä½ç‰ˆæœ¬ MySQLï¼šIN å­æŸ¥è¯¢ä¸­åŒ…å« LIMIT ä¼šæŠ¥ NotSupportedError
        try:
            if re.search(r"\bIN\s*\(\s*SELECT\b[\s\S]*?\bLIMIT\b", s, flags=re.IGNORECASE):
                issues.append("in_subquery_with_limit")
        except Exception:
            pass

        # æœªæ˜ç¡®è¦æ±‚â€œå·²éªŒè¯/çœŸå®â€å´ä½¿ç”¨ is_verified è¿‡æ»¤
        try:
            nq = (natural_query or "")
            nq_lower = nq.lower()
            wants_verified = any(kw in nq for kw in ["å·²éªŒè¯", "éªŒè¯", "çœŸå®å¾®ä¿¡å·", "å®å", "å·²æ·»åŠ å¾®ä¿¡"]) or \
                              any(kw in nq_lower for kw in ["verified", "real wechat", "real name"])
            if not wants_verified and re.search(r"\bis_verified\s*=\s*1\b", s, flags=re.IGNORECASE):
                issues.append("unwarranted_is_verified_filter")
        except Exception:
            pass

        # é¡¶å±‚ LIMIT åœ¨ ORDER BY ä¹‹å‰ï¼ˆè¯­æ³•é”™è¯¯ 1064ï¼‰
        try:
            order_idx = self._find_top_level_clause_index(s, clause="ORDER BY")
            limit_idx = self._find_top_level_clause_index(s, clause="LIMIT")
            if (order_idx is not None) and (limit_idx is not None) and (limit_idx < order_idx):
                issues.append("top_level_limit_before_orderby")
        except Exception:
            pass
        
        # æ£€æµ‹ï¼šDISTINCT + ORDER BY ä½¿ç”¨æœªåœ¨ SELECT åˆ—è¡¨ä¸­çš„åˆ—ï¼ˆMySQL 3065ï¼‰
        try:
            if re.search(r"^\s*SELECT\s+DISTINCT\b", s, flags=re.IGNORECASE):
                m_sel = re.search(r"^\s*SELECT\s+DISTINCT\s+([\s\S]+?)\s+FROM\s+", s, flags=re.IGNORECASE)
                m_ob = re.search(r"\bORDER\s+BY\s+([\s\S]+?)(?:\bLIMIT\b|;|$)", s, flags=re.IGNORECASE)
                if m_sel and m_ob:
                    select_part = m_sel.group(1)
                    order_part = m_ob.group(1)
                    order_exprs = [e.strip() for e in re.split(r",", order_part) if e.strip()]
                    def _strip_dir(e: str) -> str:
                        return re.sub(r"\s+(ASC|DESC)\b", "", e, flags=re.IGNORECASE).strip()
                    missing = []
                    for e in order_exprs:
                        base = _strip_dir(e)
                        if not re.search(re.escape(base), select_part, flags=re.IGNORECASE):
                            missing.append(base)
                    if missing:
                        issues.append("distinct_orderby_not_in_select")
        except Exception:
            pass
        return issues

    def _review_and_fix_sql(self, natural_query: str, sql: str) -> str:
        issues = self._static_sql_issues(sql, natural_query)
        if not issues:
            return sql
        # å…ˆè¿›è¡Œå·²çŸ¥å¯ç¡®å®šçš„è§„åˆ™ä¿®å¤
        fixed_sql = sql
        try:
            parents_alias_m = re.search(r"\bFROM\s+parents\s+(\w+)", fixed_sql, flags=re.IGNORECASE)
            pc_alias_m = re.search(r"\bJOIN\s+parent_contacts\s+(\w+)", fixed_sql, flags=re.IGNORECASE)
            if parents_alias_m and pc_alias_m and ("wrong_join_parent_contacts" in issues):
                p_alias = parents_alias_m.group(1)
                pc_alias = pc_alias_m.group(1)
                fixed_sql = re.sub(
                    rf"\bON\s+{re.escape(p_alias)}\.parent_id\s*=\s*{re.escape(pc_alias)}\.parent_id\b",
                    f"ON {p_alias}.id = {pc_alias}.parent_id",
                    fixed_sql,
                    flags=re.IGNORECASE
                )
        except Exception:
            pass

        # ä¿®å¤ï¼šIN å­æŸ¥è¯¢åŒ…å« LIMITï¼Œæ”¹å†™ä¸º JOIN æ´¾ç”Ÿè¡¨
        try:
            if "in_subquery_with_limit" in issues:
                fixed_sql = self._rewrite_in_with_limit_to_join(fixed_sql)
        except Exception:
            pass

        # ä¿®å¤ï¼šæœªè¦æ±‚éªŒè¯å´è¿‡æ»¤ is_verified=1ï¼Œåˆ é™¤è¯¥æ¡ä»¶
        try:
            if "unwarranted_is_verified_filter" in issues:
                fixed_sql = self._remove_unwarranted_is_verified(fixed_sql)
        except Exception:
            pass

        # ä¿®å¤ï¼šé¡¶å±‚ LIMIT/ORDER BY é¡ºåºï¼ˆè‹¥é”™è¯¯åˆ™è‡ªåŠ¨é‡æ’ï¼Œå…è®¸å›é€€ç­–ç•¥ï¼‰
        try:
            fixed_sql = self._reorder_top_level_order_limit(fixed_sql)
        except Exception:
            pass

        # ä¿®å¤ï¼šDISTINCT + ORDER BY éé€‰æ‹©åˆ— â€”â€” æ”¹å†™ä¸ºåˆ†ç»„æ´¾ç”Ÿè¡¨æ’åº
        try:
            if "distinct_orderby_not_in_select" in issues:
                fixed_sql = self._fix_distinct_orderby_not_in_select(fixed_sql)
        except Exception:
            pass

        # å¦‚ä»å­˜åœ¨å…¶ä»–é—®é¢˜ï¼Œäº¤ç”± LLM è¿›è¡Œå®¡æŸ¥ä¿®å¤
        try:
            fixed = self._llm_review_sql_openai(natural_query, fixed_sql, issues)
            return fixed or fixed_sql
        except Exception:
            return fixed_sql

    def _rewrite_in_with_limit_to_join(self, sql: str) -> str:
        """å°† WHERE <alias>.id IN (SELECT ... LIMIT N) æ”¹å†™ä¸º JOIN æ´¾ç”Ÿè¡¨å½¢å¼ã€‚
        è¯¥æ”¹å†™ä¸»è¦å…¼å®¹è¾ƒæ—§ MySQL ç‰ˆæœ¬ï¼Œé¿å… "LIMIT & IN subquery" é”™è¯¯ã€‚
        """
        s = sql
        # 1) è·å– parents è¡¨åˆ«åï¼ˆæ”¯æŒå¸¦åº“åæˆ–ä¸å¸¦åº“åï¼‰
        m_alias = re.search(r"\bFROM\s+(?:lead_management\.)?parents\s+(\w+)\b", s, flags=re.IGNORECASE)
        alias = m_alias.group(1) if m_alias else None
        if not alias:
            return sql
        # 2) æ‰¾åˆ° IN å­æŸ¥è¯¢å—
        m_in = re.search(rf"{re.escape(alias)}\.id\s+IN\s*\(\s*(SELECT[\s\S]+?)\s*\)", s, flags=re.IGNORECASE)
        if not m_in:
            return sql
        inner_select = m_in.group(1).strip()
        # 3) æ„é€  JOIN æ´¾ç”Ÿè¡¨è¯­å¥
        join_clause = f"INNER JOIN ({inner_select}) AS recent_parent_ids ON {alias}.id = recent_parent_ids.parent_id"

        # 4) æ’å…¥ JOINï¼šç´§è·Ÿåœ¨çˆ¶è¡¨ä¹‹å
        m_from_parents = re.search(r"\bFROM\s+(?:lead_management\.)?parents\s+\w+", s, flags=re.IGNORECASE)
        if not m_from_parents:
            return sql
        insert_pos = m_from_parents.end()
        s_with_join = s[:insert_pos] + "\n " + join_clause + s[insert_pos:]

        # 5) ç®€åŒ–åˆ é™¤ï¼šç§»é™¤ WHERE ä¸­çš„ IN å­æŸ¥è¯¢è°“è¯ï¼ˆå¯¹å½“å‰é—®é¢˜åœºæ™¯è¶³å¤Ÿï¼‰
        s_final = re.sub(
            rf"\bWHERE\s+{re.escape(alias)}\.id\s+IN\s*\(\s*SELECT[\s\S]+?\)\s*",
            " ",
            s_with_join,
            flags=re.IGNORECASE
        )
        return s_final

    def _find_top_level_clause_index(self, s: str, clause: str) -> Optional[int]:
        """æŸ¥æ‰¾é¡¶å±‚ï¼ˆæ‹¬å·æ·±åº¦ä¸º0ï¼‰æŒ‡å®šå­å¥çš„èµ·å§‹ç´¢å¼•ã€‚å¤§å°å†™ä¸æ•æ„Ÿã€‚"""
        pattern = re.compile(r"\b" + re.escape(clause).replace(" ", "\\s+") + r"\b", re.IGNORECASE)
        for m in pattern.finditer(s):
            pos = m.start()
            depth = 0
            for ch in s[:pos]:
                if ch == '(': depth += 1
                elif ch == ')': depth = max(0, depth - 1)
            if depth == 0:
                return pos
        return None

    def _reorder_top_level_order_limit(self, s: str) -> str:
        """ç¡®ä¿é¡¶å±‚ ORDER BY åœ¨ LIMIT ä¹‹å‰ã€‚è‹¥å‘ç° LIMIT åœ¨ ORDER BY å‰åˆ™è¿›è¡Œé‡æ’ã€‚"""
        order_idx = self._find_top_level_clause_index(s, "ORDER BY")
        limit_idx = self._find_top_level_clause_index(s, "LIMIT")
        # å›é€€ç­–ç•¥ï¼šè‹¥é¡¶å±‚è¯†åˆ«å¤±è´¥ï¼Œä½¿ç”¨å…¨å±€æœ€åå‡ºç°ä½ç½®ä½œä¸ºè¿‘ä¼¼é¡¶å±‚
        if order_idx is None:
            order_idx = s.upper().rfind("ORDER BY")
        if limit_idx is None:
            limit_idx = s.upper().rfind("LIMIT")
        if order_idx is None or limit_idx is None or order_idx < 0 or limit_idx < 0:
            return s
        if limit_idx < order_idx:
            limit_start = limit_idx
            limit_end = order_idx
            order_start = order_idx
            semi_idx = s.rfind(';')
            if semi_idx == -1:
                order_end = len(s)
                suffix = ""
            else:
                order_end = semi_idx
                suffix = s[semi_idx:]
            prefix = s[:limit_start]
            limit_clause = s[limit_start:limit_end].strip()
            order_clause = s[order_start:order_end].strip()
            rebuilt = prefix.rstrip() + "\n" + order_clause + " " + limit_clause + suffix
            return rebuilt
        return s

    def _fix_distinct_orderby_not_in_select(self, sql: str) -> str:
        """ä¿®å¤ MySQL 3065ï¼šå½“ SELECT DISTINCT ä¸ ORDER BY çš„åˆ—ä¸åœ¨é€‰æ‹©åˆ—è¡¨ä¸­æ—¶ï¼Œ
        æ”¹å†™ä¸ºï¼šå¯¹ DISTINCT é€‰æ‹©åˆ—åšåˆ†ç»„ï¼Œå¹¶å¯¹æ’åºåˆ—åšèšåˆï¼ˆMAX/MINï¼‰ï¼Œåœ¨å¤–å±‚æŒ‰èšåˆç»“æœæ’åºã€‚
        å½¢æ€ï¼š
        SELECT <distinct_cols> FROM (
          SELECT <distinct_cols>, AGG(order_col1) AS __order_col1, ...
          FROM ...
          GROUP BY <distinct_cols>
        ) t ORDER BY __order_col1 [ASC|DESC], ... [LIMIT ...];
        """
        s = (sql or "").strip()
        if not re.search(r"^\s*SELECT\s+DISTINCT\b", s, flags=re.IGNORECASE):
            return sql
        # ä½¿ç”¨æ­£åˆ™ç›´æ¥å®šä½ FROM ä¸ ORDER BYï¼Œé¿å…é¡¶å±‚è¯†åˆ«å¤±è´¥å¯¼è‡´ä¸æ”¹å†™
        m_sel = re.search(r"^\s*SELECT\s+DISTINCT\s+([\s\S]+?)\s+FROM\s+", s, flags=re.IGNORECASE)
        if not m_sel:
            return sql
        select_part = m_sel.group(1).strip()
        m_from = re.search(r"\bFROM\b", s, flags=re.IGNORECASE)
        m_order = re.search(r"\bORDER\s+BY\s+([\s\S]+?)(?:\bLIMIT\b|;|$)", s, flags=re.IGNORECASE)
        if not m_order:
            return sql
        if not m_from:
            return sql
        order_start_idx = m_order.start()
        from_start_idx = m_from.start()
        body_until_order = s[from_start_idx:order_start_idx].rstrip()
        order_part = m_order.group(1).strip()
        m_limit = re.search(r"\bLIMIT\s+[\d\s,]+(?:;|$)", s, flags=re.IGNORECASE)
        limit_clause = m_limit.group(0).strip() if m_limit else ""

        raw_order_items = [i.strip() for i in re.split(r",", order_part) if i.strip()]
        order_items = []  # [(expr, dir, alias)]
        for idx, item in enumerate(raw_order_items, start=1):
            m_dir = re.search(r"\b(ASC|DESC)\b", item, flags=re.IGNORECASE)
            direction = (m_dir.group(1).upper() if m_dir else "ASC")
            expr = re.sub(r"\bASC\b|\bDESC\b", "", item, flags=re.IGNORECASE).strip()
            alias = f"__order_col{idx}"
            order_items.append((expr, direction, alias))

        agg_parts = []
        order_outer_parts = []
        for expr, direction, alias in order_items:
            agg_fn = "MAX" if direction == "DESC" else "MIN"
            agg_parts.append(f"{agg_fn}({expr}) AS {alias}")
            order_outer_parts.append(f"{alias} {direction}")

        inner_select = f"SELECT {select_part}, " + ", ".join(agg_parts) + f"\n{body_until_order}\n GROUP BY {select_part}"
        # å¤–å±‚é€‰æ‹©åˆ—éœ€å»é™¤è¡¨åˆ«åå‰ç¼€æˆ–é‡‡ç”¨åˆ«å
        select_items = [i.strip() for i in re.split(r",", select_part) if i.strip()]
        outer_labels = []
        for item in select_items:
            m_as = re.search(r"\bAS\s+([A-Za-z_][A-Za-z0-9_]*)\b", item, flags=re.IGNORECASE)
            if m_as:
                outer_labels.append(m_as.group(1))
                continue
            m_col = re.search(r"\b([A-Za-z_][A-Za-z0-9_]*)\.([A-Za-z_][A-Za-z0-9_]*)\b", item)
            if m_col:
                outer_labels.append(m_col.group(2))
                continue
            # å°è¯•ç›´æ¥å–æœ€åçš„æ ‡è¯†ç¬¦ä½œä¸ºåˆ—å
            m_plain = re.findall(r"[A-Za-z_][A-Za-z0-9_]*", item)
            outer_labels.append(m_plain[-1] if m_plain else f"col_{len(outer_labels)+1}")

        outer_select = (
            "SELECT " + ", ".join(outer_labels) + " FROM (\n" +
            inner_select + "\n) AS __t\n ORDER BY " + ", ".join(order_outer_parts)
        )
        if limit_clause:
            outer_select += f" {limit_clause.rstrip(';')}"
        if s.endswith(";"):
            outer_select += ";"
        return outer_select

    def _remove_unwarranted_is_verified(self, sql: str) -> str:
        """åˆ é™¤ WHERE/AND ä¸­çš„ is_verified=1 æ¡ä»¶ï¼ˆå½“ç”¨æˆ·æœªè¦æ±‚"å·²éªŒè¯"æ—¶ï¼‰ã€‚"""
        s = sql
        # åˆ é™¤ AND åˆ—è¡¨ä¸­çš„è¿‡æ»¤é¡¹
        s = re.sub(r"\s+AND\s+\w+\.is_verified\s*=\s*1\b", "", s, flags=re.IGNORECASE)
        # åˆ é™¤ "WHERE is_verified=1 AND"ï¼Œä¿ç•™å…¶ä»–æ¡ä»¶
        s = re.sub(r"\bWHERE\s+\w+\.is_verified\s*=\s*1\s+AND\s+", " WHERE ", s, flags=re.IGNORECASE)
        # åˆ é™¤å­¤ç«‹çš„ "WHERE is_verified=1"
        s = re.sub(r"\bWHERE\s+\w+\.is_verified\s*=\s*1\b", " ", s, flags=re.IGNORECASE)
        return s

    def _llm_review_sql_openai(self, natural_query: str, sql: str, issues: List[str]) -> str:
        base_url = getattr(config, 'OPENAI_BASE_URL', '')
        model = getattr(config, 'OPENAI_MODEL', 'gpt-4o-mini')
        api_key = getattr(config, 'OPENAI_API_KEY', '')
        endpoint = base_url.rstrip('/') + '/chat/completions'
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json',
            'Accept': 'application/json'
        }
        system_prompt = (
            "ä½ æ˜¯ä¸¥æ ¼çš„ MySQL SQL å®¡æŸ¥ä¸ä¿®å¤åŠ©æ‰‹ã€‚\n"
            "ä»»åŠ¡ï¼šæ ¹æ®ç”¨æˆ·æ„å›¾ä¸é—®é¢˜æ¸…å•ï¼Œç»™å‡ºå¯æ‰§è¡Œä¸”æ›´åˆç†çš„ SQLã€‚\n"
            "è¦æ±‚ï¼š\n"
            "- ä»…è¿”å›ä¸€æ¡ä¿®æ­£åçš„ SQLï¼Œä¸è¦è§£é‡Šã€‚\n"
            "- åªå…è®¸ SELECT æŸ¥è¯¢ï¼Œç¦æ­¢ DDL/DMLã€‚\n"
            "- è‹¥ç”¨æˆ·æ„å›¾ä¸º åç§°/åå•/åˆ—è¡¨ï¼Œå¿…é¡»è¿”å›æ˜ç»†åˆ—è¡¨ï¼ˆéèšåˆï¼‰ï¼Œä¼˜å…ˆä½¿ç”¨ parents.parent_codeã€‚\n"
            "- â€˜æœ¬å‘¨/è¿™å‘¨â€™ ç”¨ YEARWEEK(created_at,1)=YEARWEEK(CURDATE(),1)ï¼›â€˜è¿‡å»ä¸€å‘¨/è¿‘ä¸€å‘¨/ä¸€å‘¨â€™ ç”¨æœ€è¿‘7å¤©ã€‚\n"
            "- è‹¥å­˜åœ¨èšåˆä¸”åŒ…å«éèšåˆåˆ—ï¼Œå¿…é¡»è¡¥å…… GROUP BY æˆ–æ”¹ä¸ºæ˜ç»†ã€‚\n"
            "- å¯¹æ˜ç»†ç»“æœé™åˆ¶ä¸º LIMIT 50ï¼Œå¹¶æŒ‰ created_at DESC æ’åºã€‚\n"
            "- å…³è” parent_contacts æ—¶ï¼Œå¿…é¡»ä½¿ç”¨ parents.id = parent_contacts.parent_id è¿›è¡Œè¿æ¥ï¼Œä¸å­˜åœ¨ parents.parent_id å­—æ®µã€‚\n"
            "- è”ç³»æ–¹å¼è¿‡æ»¤ï¼šé™¤éç”¨æˆ·æ˜ç¡®è¦æ±‚â€˜å·²éªŒè¯/éªŒè¯è¿‡/çœŸå®â€™ï¼Œä¸è¦åŠ å…¥ is_verified = 1ï¼›å¦‚éœ€ä¸»è”ç³»æ–¹å¼ï¼Œä»…ä½¿ç”¨ is_primary = 1ã€‚\n"
            "- å…¼å®¹æ€§ï¼šé¿å…åœ¨ IN/EXISTS å­æŸ¥è¯¢ä¸­ä½¿ç”¨ LIMITï¼Œè¯·æ”¹å†™ä¸º JOIN æ´¾ç”Ÿè¡¨ä»¥å®ç°é™åˆ¶ã€‚\n"
        )
        messages = [
            {'role': 'system', 'content': system_prompt},
            {
                'role': 'user',
                'content': (
                    f"ç”¨æˆ·æ„å›¾: {natural_query}\n"
                    f"å·²ç”Ÿæˆ SQL: {sql}\n"
                    f"æ£€æµ‹åˆ°é—®é¢˜: {', '.join(issues)}\n"
                    "è¯·è¾“å‡ºä¿®æ­£åçš„ SQLï¼ˆä»… SQLï¼‰ã€‚"
                )
            }
        ]
        payload = {
            'model': model,
            'temperature': 0.0,
            'messages': messages
        }
        resp = requests.post(endpoint, headers=headers, json=payload, timeout=30)
        if resp.status_code != 200:
            raise Exception(f"LLMæ¥å£é”™è¯¯: {resp.status_code} {resp.text}")
        data = resp.json()
        content = (
            data.get('choices', [{}])[0]
            .get('message', {})
            .get('content', '')
        )
        if not content:
            raise Exception("LLMæ— è¿”å›å†…å®¹")
        fixed_sql = content.strip()
        # æ¸…ç†markdown
        if fixed_sql.startswith("```sql"):
            fixed_sql = fixed_sql[6:]
        if fixed_sql.startswith("```"):
            fixed_sql = fixed_sql[3:]
        if fixed_sql.endswith("```"):
            fixed_sql = fixed_sql[:-3]
        return fixed_sql.strip()

    def _llm_generate_sql_openai(self, query: str, history: Optional[str] = None) -> str:
        """é€šè¿‡ OpenAI/Moonshot ç›´è¿æ¥å£ç”Ÿæˆ SQLï¼Œé¿å… transformers/torch ä¾èµ–"""
        base_url = getattr(config, 'OPENAI_BASE_URL', '')
        model = getattr(config, 'OPENAI_MODEL', 'gpt-4o-mini')
        api_key = getattr(config, 'OPENAI_API_KEY', '')
        if not (base_url and model and api_key):
            raise Exception("ç¼ºå°‘ OPENAI é…ç½®")

        # å…¼å®¹ OpenAI ä¸ Moonshot çš„ chat/completions æ¥å£
        endpoint = base_url.rstrip('/') + '/chat/completions'
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json',
            'Accept': 'application/json'
        }
        db_schema = self._get_mschema_str()
        payload = {
            'model': model,
            'temperature': 0.1,
            'messages': [
                {'role': 'system', 'content': self._get_system_prompt()},
                {'role': 'user', 'content': f"ç”¨æˆ·æŸ¥è¯¢ï¼š{query}\n\nä¼šè¯ä¸Šä¸‹æ–‡ï¼ˆæœ€è¿‘å‡ è½®ï¼‰ï¼š\n{history or ''}\n\né™„åŠ æ•°æ®åº“ç†è§£ï¼ˆSchemaï¼‰ï¼š\n{db_schema}\nè¯·ç”Ÿæˆå¯¹åº”çš„SQLæŸ¥è¯¢è¯­å¥ã€‚ä»…è¾“å‡ºSQLï¼Œä¸è¦è§£é‡Šã€‚ä¸è¦ä½¿ç”¨åå¼•å·ã€‚"}
            ]
        }
        try:
            resp = requests.post(endpoint, headers=headers, json=payload, timeout=30)
            if resp.status_code != 200:
                raise Exception(f"LLMæ¥å£é”™è¯¯: {resp.status_code} {resp.text}")
            data = resp.json()
            # OpenAI/Moonshot å…¼å®¹ï¼šchoices[0].message.content
            content = (
                data.get('choices', [{}])[0]
                .get('message', {})
                .get('content', '')
            )
            if not content:
                raise Exception("LLMæ— è¿”å›å†…å®¹")
            sql = content.strip()
            # æ¸…ç†markdown
            if sql.startswith("```sql"):
                sql = sql[6:]
            if sql.startswith("```"):
                sql = sql[3:]
            if sql.endswith("```"):
                sql = sql[:-3]
            return sql.strip()
        except Exception as e:
            app_logger.error(f"OpenAIç›´è¿ç”ŸæˆSQLå¤±è´¥: {e}")
            # å¤±è´¥æ—¶ä»å›é€€è§„åˆ™åŒ–ï¼Œæå‡å¯ç”¨æ€§
            return self._rule_based_sql(query)
    
    def execute_sql(self, sql: str) -> Dict[str, Any]:
        """æ‰§è¡ŒSQLæŸ¥è¯¢"""
        db = SessionLocal()
        try:
            # å®‰å…¨æ£€æŸ¥ï¼šåªå…è®¸SELECTæŸ¥è¯¢
            sql_upper = sql.upper().strip()
            if not sql_upper.startswith('SELECT'):
                raise Exception("åªå…è®¸æ‰§è¡ŒSELECTæŸ¥è¯¢")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å±é™©å…³é”®è¯ï¼ˆæ•´è¯åŒ¹é…ï¼Œé¿å…è¯¯ä¼¤å¦‚ created_at / updated_atï¼‰
            dangerous_pattern = re.compile(r"\b(DROP|DELETE|UPDATE|INSERT|ALTER|CREATE|TRUNCATE|REPLACE|MERGE|GRANT|REVOKE)\b", re.IGNORECASE)
            if dangerous_pattern.search(sql):
                # æå–å…·ä½“å…³é”®è¯ç”¨äºæç¤º
                match = dangerous_pattern.search(sql)
                keyword = match.group(1).upper() if match else 'UNKNOWN'
                raise Exception(f"SQLæŸ¥è¯¢åŒ…å«å±é™©å…³é”®è¯: {keyword}")
            
            # æ‰§è¡ŒæŸ¥è¯¢
            result = db.execute(text(sql))
            
            # è·å–åˆ—å
            columns = list(result.keys()) if result.keys() else []
            
            # è·å–æ•°æ®
            rows = result.fetchall()
            
            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            data = []
            for row in rows:
                row_dict = {}
                for i, column in enumerate(columns):
                    value = row[i]
                    # å¤„ç†æ—¥æœŸæ—¶é—´ç±»å‹
                    if hasattr(value, 'isoformat'):
                        value = value.isoformat()
                    row_dict[column] = value
                data.append(row_dict)
            
            return MessageFormatter.format_query_result(
                data=data,
                total=len(data),
                query=sql
            )
            
        except Exception as e:
            err_text = str(e)
            app_logger.error(f"æ‰§è¡ŒSQLå¤±è´¥: {err_text}")
            # å…¼å®¹å¤„ç†ï¼šä½ç‰ˆæœ¬ MySQL ä¸æ”¯æŒ IN å­æŸ¥è¯¢ä¸­ä½¿ç”¨ LIMITï¼Œå°è¯•æ”¹å†™å¹¶é‡è¯•
            if "LIMIT & IN/ALL/ANY/SOME subquery" in err_text:
                try:
                    rewritten = self._rewrite_in_with_limit_to_join(sql)
                    if rewritten and rewritten != sql:
                        app_logger.info("è‡ªåŠ¨ä¿®å¤ SQLï¼šå°† IN+LIMIT æ”¹å†™ä¸º JOIN æ´¾ç”Ÿè¡¨åé‡è¯•æ‰§è¡Œ")
                        result = db.execute(text(rewritten))
                        columns = list(result.keys()) if result.keys() else []
                        rows = result.fetchall()
                        data = []
                        for row in rows:
                            row_dict = {}
                            for i, column in enumerate(columns):
                                value = row[i]
                                if hasattr(value, 'isoformat'):
                                    value = value.isoformat()
                                row_dict[column] = value
                            data.append(row_dict)
                        return MessageFormatter.format_query_result(
                            data=data,
                            total=len(data),
                            query=rewritten
                        )
                except Exception as e2:
                    app_logger.warning(f"è‡ªåŠ¨ä¿®å¤å¤±è´¥: {e2}")
            # å…¼å®¹å¤„ç†ï¼šMySQL 3065 â€”â€” DISTINCT + ORDER BY éé€‰æ‹©åˆ—ï¼Œå°è¯•æ”¹å†™ä¸ºåˆ†ç»„æ´¾ç”Ÿè¡¨å¹¶é‡è¯•
            if ("incompatible with DISTINCT" in err_text) or (
                ("not in SELECT list" in err_text) and ("DISTINCT" in sql.upper())
            ):
                try:
                    rewritten = self._fix_distinct_orderby_not_in_select(sql)
                    if rewritten and rewritten != sql:
                        app_logger.info("è‡ªåŠ¨ä¿®å¤ SQLï¼šDISTINCT+ORDER BY éé€‰æ‹©åˆ—æ”¹å†™ä¸ºåˆ†ç»„æ´¾ç”Ÿè¡¨åé‡è¯•æ‰§è¡Œ")
                        result = db.execute(text(rewritten))
                        columns = list(result.keys()) if result.keys() else []
                        rows = result.fetchall()
                        data = []
                        for row in rows:
                            row_dict = {}
                            for i, column in enumerate(columns):
                                value = row[i]
                                if hasattr(value, 'isoformat'):
                                    value = value.isoformat()
                                row_dict[column] = value
                            data.append(row_dict)
                        return MessageFormatter.format_query_result(
                            data=data,
                            total=len(data),
                            query=rewritten
                        )
                except Exception as e2:
                    app_logger.warning(f"è‡ªåŠ¨ä¿®å¤å¤±è´¥: {e2}")
            # è¿”å›ç”¨æˆ·å‹å¥½é”™è¯¯ï¼Œä¸æš´éœ²æŠ€æœ¯ç»†èŠ‚
            return MessageFormatter.format_error_response("æŸ¥è¯¢æ‰§è¡Œé‡åˆ°é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•æˆ–ç®€åŒ–æŸ¥è¯¢ã€‚")
        finally:
            db.close()

    async def query(self, natural_query: str) -> Dict[str, Any]:
        """å¤„ç†è‡ªç„¶è¯­è¨€æŸ¥è¯¢"""
        try:
            app_logger.info(f"å¤„ç†æŸ¥è¯¢: {natural_query}")
            
            # ç”ŸæˆSQL
            sql = await self.generate_sql(natural_query)
            
            # æ‰§è¡ŒSQL
            result = self.execute_sql(sql)
            
            # æ·»åŠ åŸå§‹æŸ¥è¯¢ä¿¡æ¯
            if result.get('success'):
                result['natural_query'] = natural_query
                result['generated_sql'] = sql
            
            return result
            
        except Exception as e:
            app_logger.error(f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {e}")
            return MessageFormatter.format_error_response(f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}")

    # å·¥å…·å°è£…ï¼šä¾› LangGraph è°ƒç”¨
    def get_mschema(self) -> str:
        """å…¬å¼€æ–¹æ³•ï¼šè¿”å› M-Schema å­—ç¬¦ä¸²"""
        return self._get_mschema_str()

    def evaluate_and_fix_sql(self, natural_query: str, sql: str) -> str:
        """å…¬å¼€æ–¹æ³•ï¼šè¯„ä¼°å¹¶ä¿®å¤ SQL"""
        return self._review_and_fix_sql(natural_query, sql)

    def summarize_result(self, natural_query: str, sql: str, result: Dict[str, Any], history: Optional[str] = None) -> str:
        """æ ¹æ®æŸ¥è¯¢ç»“æœç”Ÿæˆè‡ªç„¶è¯­è¨€æ€»ç»“ã€‚ä¼˜å…ˆä½¿ç”¨ LLMï¼Œå¤±è´¥åˆ™å›é€€è§„åˆ™åŒ–æ€»ç»“ã€‚"""
        try:
            if not result.get('success'):
                return f"âŒ æŸ¥è¯¢å¤±è´¥ï¼š{result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            # ä¼˜å…ˆä½¿ç”¨ç›´è¿ LLM
            base_url = getattr(config, 'OPENAI_BASE_URL', '')
            model = getattr(config, 'OPENAI_MODEL', 'gpt-4o-mini')
            api_key = getattr(config, 'OPENAI_API_KEY', '')
            if base_url and model and api_key:
                summary, thoughts = self._llm_summarize_result_openai(natural_query, sql, result, history)
                # æ‰“å°æ€ç»´é“¾å†…å®¹åˆ°æ§åˆ¶å°
                if thoughts:
                    app_logger.info("æ€ç»´é“¾å†…å®¹:\n" + thoughts)
                return summary
        except Exception as e:
            app_logger.warning(f"LLM æ€»ç»“å¤±è´¥ï¼Œå›é€€è§„åˆ™åŒ–ï¼š{e}")
        # è§„åˆ™åŒ–å›é€€
        data = result.get('data', [])
        total = result.get('total', 0)
        if total == 0:
            return "ğŸ“Š æ²¡æœ‰æŸ¥è¯¢åˆ°ç›¸å…³è®°å½•ã€‚"
        # è‹¥åŒ…å«åå­—/åç§°åˆ—ï¼Œæ‹¼æ¥å‹å¥½åˆ—è¡¨
        name_keys = ['staff_id', 'name', 'nickname', 'sales_name', 'operator_name']
        first_row = data[0] if data else {}
        key_for_name = next((k for k in first_row.keys() if any(nk in k.lower() for nk in name_keys)), None)
        if key_for_name:
            names = [str(row.get(key_for_name)) for row in data if row.get(key_for_name) is not None]
            names = [n for n in names if n]
            unique_names = []
            for n in names:
                if n not in unique_names:
                    unique_names.append(n)
            if unique_names:
                joined = 'ã€'.join(unique_names[:10])
                more = f"ï¼Œç­‰{len(unique_names)}äºº" if len(unique_names) > 10 else ""
                return f"ğŸ“£ è¿™å‘¨æˆäº¤çš„å¯¹åº”é”€å”®åå­—ï¼š{joined}{more}ã€‚"
        # å¦åˆ™è¿”å›å¼ºåŒ–ç‰ˆè¡¨æ ¼æ‘˜è¦
        return self.format_query_response(result)

    def _llm_summarize_result_openai(self, natural_query: str, sql: str, result: Dict[str, Any], history: Optional[str] = None) -> tuple[str, str]:
        """é€šè¿‡ OpenAI/Moonshot ç›´è¿æ¥å£å¯¹ç»“æœåšè‡ªç„¶è¯­è¨€æ€»ç»“ï¼Œè¿”å› (summary, thoughts_text)ã€‚"""
        base_url = getattr(config, 'OPENAI_BASE_URL', '')
        model = getattr(config, 'OPENAI_MODEL', 'gpt-4o-mini')
        api_key = getattr(config, 'OPENAI_API_KEY', '')
        endpoint = base_url.rstrip('/') + '/chat/completions'
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json',
            'Accept': 'application/json'
        }
        data = result.get('data', [])
        total = result.get('total', 0)
        sample_limit = 10
        sample_rows = data[:sample_limit]
        def _row_to_text(row: Dict[str, Any]) -> str:
            parts = []
            for k, v in row.items():
                if v is None:
                    continue
                if hasattr(v, 'isoformat'):
                    v = v.isoformat()
                parts.append(f"{k}={v}")
            return ", ".join(parts)
        sample_text = "\n".join(_row_to_text(r) for r in sample_rows) or "(æ— ç¤ºä¾‹æ•°æ®)"
        system_prompt = (
            "ä½ æ˜¯ç¾¤èŠé‡Œçš„æ•°æ®åŠ©ç†ã€‚é˜…è¯»SQLæŸ¥è¯¢ç»“æœï¼Œç”¨ä¸­æ–‡è¾“å‡ºç®€æ´ã€è‡ªç„¶çš„æ€»ç»“ã€‚"\
            "è¾“å‡ºä¸¤ä¸ªéƒ¨åˆ†ï¼š\n"\
            "æ€ç»´é“¾ï¼šç”¨1-6è¡Œè¯´æ˜ä½ å¦‚ä½•åˆ†æï¼ˆä¸è¦æ³„éœ²éšç§æˆ–SQLç»†èŠ‚ï¼‰ã€‚\n"\
            "æœ€ç»ˆå›å¤ï¼šä¸€æ®µé€‚åˆç¾¤èŠçš„ç®€çŸ­è‡ªç„¶è¯­è¨€ï¼Œé¿å…æŠ€æœ¯ç»†èŠ‚ï¼Œå¿…è¦æ—¶åˆ—å‡ºå…³é”®åå­—æˆ–æ•°é‡ã€‚"
        )
        user_prompt = (
            f"ç”¨æˆ·æŸ¥è¯¢ï¼š{natural_query}\n"\
            f"SQLï¼š{sql}\n"\
            f"ç»“æœè¡Œæ•°ï¼š{total}\n"\
            f"ç¤ºä¾‹æ•°æ®ï¼ˆæœ€å¤š{sample_limit}è¡Œï¼‰ï¼š\n{sample_text}\n"\
            f"ä¼šè¯ä¸Šä¸‹æ–‡ï¼ˆæœ€è¿‘å‡ è½®ï¼‰ï¼š\n{history or ''}\n"\
            "è¯·ä¸¥æ ¼ä»¥å¦‚ä¸‹æ ¼å¼è¿”å›ï¼š\næ€ç»´é“¾: ...\næœ€ç»ˆå›å¤: ..."
        )
        payload = {
            'model': model,
            'temperature': 0.2,
            'messages': [
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_prompt}
            ]
        }
        resp = requests.post(endpoint, headers=headers, json=payload, timeout=30)
        if resp.status_code != 200:
            raise Exception(f"LLMæ¥å£é”™è¯¯: {resp.status_code} {resp.text}")
        data_json = resp.json()
        content = (
            data_json.get('choices', [{}])[0]
            .get('message', {})
            .get('content', '')
        )
        if not content:
            raise Exception("LLMæ— è¿”å›å†…å®¹")
        text = content.strip()
        # å°è¯•è§£æä¸¤æ®µå¼è¾“å‡º
        thoughts_text = ""
        summary_text = text
        try:
            m1 = re.search(r"æ€ç»´é“¾\s*[:ï¼š]\s*(.*?)(?:\n\s*æœ€ç»ˆå›å¤\s*[:ï¼š])", text, flags=re.DOTALL)
            m2 = re.search(r"æœ€ç»ˆå›å¤\s*[:ï¼š]\s*(.*)$", text, flags=re.DOTALL)
            if m1:
                thoughts_text = m1.group(1).strip()
            if m2:
                summary_text = m2.group(1).strip()
        except Exception:
            thoughts_text = ""
        return summary_text, thoughts_text
    
    def get_quick_stats(self) -> Dict[str, Any]:
        """è·å–å¿«é€Ÿç»Ÿè®¡ä¿¡æ¯"""
        try:
            stats = {}
            db = SessionLocal()
            
            # æ€»å®¶é•¿æ•°
            result = db.execute(text("SELECT COUNT(*) as total FROM parents"))
            stats['total_parents'] = result.fetchone()[0]
            
            # ä»Šæ—¥æ–°å¢
            result = db.execute(text("SELECT COUNT(*) as today FROM parents WHERE DATE(created_at) = CURDATE()"))
            stats['today_new'] = result.fetchone()[0]
            
            # å„çŠ¶æ€ç»Ÿè®¡
            result = db.execute(text("""
                SELECT status, COUNT(*) as count 
                FROM parents 
                GROUP BY status
            """))
            status_stats = {}
            for row in result.fetchall():
                status_stats[row[0]] = row[1]
            stats['status_stats'] = status_stats
            
            # æœ¬æœˆæˆäº¤é‡‘é¢
            result = db.execute(text("""
                SELECT COALESCE(SUM(amount), 0) as total_amount 
                FROM process_logs 
                WHERE action_type = 'æˆäº¤' 
                AND MONTH(created_at) = MONTH(CURDATE())
                AND YEAR(created_at) = YEAR(CURDATE())
            """))
            stats['monthly_revenue'] = float(result.fetchone()[0])
            
            db.close()
            
            return MessageFormatter.format_success_response("ç»Ÿè®¡ä¿¡æ¯è·å–æˆåŠŸ", stats)
            
        except Exception as e:
            app_logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return MessageFormatter.format_error_response(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
    
    def format_query_response(self, result: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æŸ¥è¯¢å“åº”ä¸ºæ–‡æœ¬"""
        if not result.get('success'):
            return f"âŒ æŸ¥è¯¢å¤±è´¥ï¼š{result.get('error', 'æœªçŸ¥é”™è¯¯')}"
        
        data = result.get('data', [])
        total = result.get('total', 0)
        
        if total == 0:
            return "ğŸ“Š æŸ¥è¯¢ç»“æœï¼šæš‚æ— æ•°æ®"
        
        # å¦‚æœæ˜¯ç»Ÿè®¡æŸ¥è¯¢ï¼ˆåªæœ‰ä¸€è¡Œä¸€åˆ—ï¼‰
        if total == 1 and len(data[0]) == 1:
            key = list(data[0].keys())[0]
            value = data[0][key]
            return f"ğŸ“Š æŸ¥è¯¢ç»“æœï¼š{value}"
        
        # å¦‚æœæ˜¯ç®€å•çš„è®¡æ•°æŸ¥è¯¢
        if total == 1 and 'count' in str(data[0]).lower():
            for key, value in data[0].items():
                if 'count' in key.lower() or key.lower() in ['total', 'num', 'cnt']:
                    return f"ğŸ“Š æŸ¥è¯¢ç»“æœï¼š{value} æ¡è®°å½•"
        
        # æ ¼å¼åŒ–å¤šè¡Œæ•°æ®
        response = f"ğŸ“Š æŸ¥è¯¢ç»“æœï¼ˆå…± {total} æ¡ï¼‰ï¼š\n"
        
        # é™åˆ¶æ˜¾ç¤ºæ¡æ•°
        display_limit = 10
        display_data = data[:display_limit]
        
        for i, row in enumerate(display_data, 1):
            response += f"\n{i}. "
            row_parts = []
            for key, value in row.items():
                if value is not None:
                    row_parts.append(f"{key}: {value}")
            response += " | ".join(row_parts)
        
        if total > display_limit:
            response += f"\n\n... è¿˜æœ‰ {total - display_limit} æ¡è®°å½•æœªæ˜¾ç¤º"
        
        return response